{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM8MRkf8Dr94"
      },
      "source": [
        "## Describe your model -> fine-tuned LLaMA 2\n",
        "Adapted froma contribution of  Matt Shumer (https://twitter.com/mattshumer_)\n",
        "\n",
        "The goal of this notebook is to experiment with a new way to make it very easy to build a task-specific model for your use-case.\n",
        "\n",
        "First, use the best GPU available (go to Runtime -> change runtime type)\n",
        "\n",
        "To create your model, just go to the first code cell, and describe the model you want to build in the prompt. Be descriptive and clear.\n",
        "\n",
        "Select a temperature (high=creative, low=precise), and the number of training examples to generate to train the model. From there, just run all the cells.\n",
        "\n",
        "You can change the model you want to fine-tune by changing `model_name` in the `Define Hyperparameters` cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Way3_PuPpIuE"
      },
      "source": [
        "# Data generation step (optional, start for section 2, here is if you want a custom model for other use case)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lY-3DvlIpVSl"
      },
      "source": [
        "Write your prompt here. Make it as descriptive as possible!\n",
        "\n",
        "Then, choose the temperature (between 0 and 1) to use when generating data. Lower values are great for precise tasks, like writing code, whereas larger values are better for creative tasks, like writing stories.\n",
        "\n",
        "Finally, choose how many examples you want to generate. The more you generate, a) the longer it takes and b) the more expensive data generation will be. But generally, more examples will lead to a higher-quality model. 100 is usually the minimum to start."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7WKZyxtpUPS"
      },
      "outputs": [],
      "source": [
        "prompt = \"A model that takes in a puzzle-like reasoning-heavy question in English, and responds with a well-reasoned, step-by-step thought out response in Spanish.\"\n",
        "temperature = .4\n",
        "number_of_examples = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1snNou5PrIci"
      },
      "source": [
        "Run this to generate the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuL2UaqlsmBD",
        "outputId": "74446512-59ec-44cf-9a7c-01e6441154ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.25.0-py3-none-any.whl (312 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/312.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m307.2/312.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.9/312.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.25.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rdsd82ngpHCG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import random\n",
        "\n",
        "openai.api_key = \"YOUR KEY HERE\"\n",
        "\n",
        "def generate_example(prompt, prev_examples, temperature=.5):\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": f\"You are generating data which will be used to train a machine learning model.\\n\\nYou will be given a high-level description of the model we want to train, and from that, you will generate data samples, each with a prompt/response pair.\\n\\nYou will do so in this format:\\n```\\nprompt\\n-----------\\n$prompt_goes_here\\n-----------\\n\\nresponse\\n-----------\\n$response_goes_here\\n-----------\\n```\\n\\nOnly one prompt/response pair should be generated per turn.\\n\\nFor each turn, make the example slightly more complex than the last, while ensuring diversity.\\n\\nMake sure your samples are unique and diverse, yet high-quality and complex enough to train a well-performing model.\\n\\nHere is the type of model we want to train:\\n`{prompt}`\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    if len(prev_examples) > 0:\n",
        "        if len(prev_examples) > 10:\n",
        "            prev_examples = random.sample(prev_examples, 10)\n",
        "        for example in prev_examples:\n",
        "            messages.append({\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": example\n",
        "            })\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "        max_tokens=1354,\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message['content']\n",
        "\n",
        "# Generate examples\n",
        "prev_examples = []\n",
        "for i in range(number_of_examples):\n",
        "    print(f'Generating example {i}')\n",
        "    example = generate_example(prompt, prev_examples, temperature)\n",
        "    prev_examples.append(example)\n",
        "\n",
        "print(prev_examples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KC6iJzXjugJ-"
      },
      "source": [
        "We also need to generate a system message."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMcfhW6Guh2E"
      },
      "outputs": [],
      "source": [
        "def generate_system_message(prompt):\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "          {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You will be given a high-level description of the model we are training, and from that, you will generate a simple system prompt for that model to use. Remember, you are not generating the system message for data generation -- you are generating the system message to use for inference. A good format to follow is `Given $INPUT_DATA, you will $WHAT_THE_MODEL_SHOULD_DO.`.\\n\\nMake it as concise as possible. Include nothing but the system prompt in your response.\\n\\nFor example, never write: `\\\"$SYSTEM_PROMPT_HERE\\\"`.\\n\\nIt should be like: `$SYSTEM_PROMPT_HERE`.\"\n",
        "          },\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": prompt.strip(),\n",
        "          }\n",
        "        ],\n",
        "        temperature=temperature,\n",
        "        max_tokens=500,\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message['content']\n",
        "\n",
        "system_message = generate_system_message(prompt)\n",
        "\n",
        "print(f'The system message is: `{system_message}`. Feel free to re-run this cell if you want a better result.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6BqZ-hjseBF"
      },
      "source": [
        "Now let's put our examples into a dataframe and turn them into a final pair of datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CEdkYeRsdmB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Initialize lists to store prompts and responses\n",
        "prompts = []\n",
        "responses = []\n",
        "\n",
        "# Parse out prompts and responses from examples\n",
        "for example in prev_examples:\n",
        "  try:\n",
        "    split_example = example.split('-----------')\n",
        "    prompts.append(split_example[1].strip())\n",
        "    responses.append(split_example[3].strip())\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'prompt': prompts,\n",
        "    'response': responses\n",
        "})\n",
        "\n",
        "# Remove duplicates\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "print('There are ' + str(len(df)) + ' successfully-generated examples. Here are the first few:')\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-8dt5qqtpgM"
      },
      "source": [
        "Split into train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXO6WrsgQ81M"
      },
      "outputs": [],
      "source": [
        "# Split the data into train and test sets, with 90% in the train set\n",
        "train_df = df.sample(frac=0.9, random_state=42)\n",
        "test_df = df.drop(train_df.index)\n",
        "\n",
        "# Save the dataframes to .jsonl files\n",
        "train_df.to_json('train.jsonl', orient='records', lines=True)\n",
        "test_df.to_json('test.jsonl', orient='records', lines=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAOZzmYqQ9Vd"
      },
      "source": [
        "# ALTERNATIVE. Importing dataset from confluence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlnIpklGRPpT",
        "outputId": "01dbad63-4656-4647-dc23-a0083056236a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-dotenv in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (1.0.1)\n",
            "Requirement already satisfied: requests in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (2.31.0)\n",
            "Requirement already satisfied: langchain-community in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (0.0.36)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests) (2024.2.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain-community) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain-community) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain-community) (0.6.5)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.48 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain-community) (0.1.48)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain-community) (0.1.52)\n",
            "Requirement already satisfied: numpy<2,>=1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain-community) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain-core<0.2.0,>=0.1.48->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain-core<0.2.0,>=0.1.48->langchain-community) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain-core<0.2.0,>=0.1.48->langchain-community) (2.7.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.11.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.48->langchain-community) (2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.48->langchain-community) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.48->langchain-community) (2.18.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: langchain in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (0.1.17)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (0.6.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.36 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (0.0.36)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.48 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (0.1.48)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (0.1.52)\n",
            "Requirement already satisfied: numpy<2,>=1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain-core<0.2.0,>=0.1.48->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: atlassian-python-api in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (3.41.11)\n",
            "Requirement already satisfied: deprecated in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from atlassian-python-api) (1.2.14)\n",
            "Requirement already satisfied: requests in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from atlassian-python-api) (2.31.0)\n",
            "Requirement already satisfied: six in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from atlassian-python-api) (1.16.0)\n",
            "Requirement already satisfied: oauthlib in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from atlassian-python-api) (3.2.2)\n",
            "Requirement already satisfied: requests-oauthlib in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from atlassian-python-api) (2.0.0)\n",
            "Requirement already satisfied: jmespath in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from atlassian-python-api) (1.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from atlassian-python-api) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from beautifulsoup4->atlassian-python-api) (2.5)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from deprecated->atlassian-python-api) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests->atlassian-python-api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests->atlassian-python-api) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests->atlassian-python-api) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests->atlassian-python-api) (2024.2.2)\n",
            "Requirement already satisfied: lxml in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (5.2.1)\n",
            "Requirement already satisfied: tiktoken in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (0.6.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from tiktoken) (2024.4.28)\n",
            "Requirement already satisfied: requests>=2.26.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Requirement already satisfied: pandas in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: boto3 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (1.34.95)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.95 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from boto3) (1.34.95)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from boto3) (0.10.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from botocore<1.35.0,>=1.34.95->boto3) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from botocore<1.35.0,>=1.34.95->boto3) (2.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.95->boto3) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install python-dotenv requests langchain-community\n",
        "!pip install langchain\n",
        "!pip install atlassian-python-api\n",
        "!pip install lxml\n",
        "!pip install tiktoken\n",
        "!pip install pandas\n",
        "!pip install boto3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: markdownify in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (0.12.1)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.9 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from markdownify) (4.12.3)\n",
            "Requirement already satisfied: six<2,>=1.15 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from markdownify) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from beautifulsoup4<5,>=4.9->markdownify) (2.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install markdownify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K__MJLe_cbm4",
        "outputId": "469d95c2-d37f-4868-ea33-2703c84125ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Received runtime arguments {'space_key': 'EN', 'keep_markdown_format': True}. Passing runtime args to `load` is deprecated. Please pass arguments during initialization instead.\n"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "`markdownify` package not found, please run `pip install markdownify`",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "File \u001b[0;32m~/Documents/GitHub/Confluence-github-chatbot/pruebas_confluence/lib/python3.12/site-packages/langchain_community/document_loaders/confluence.py:500\u001b[0m, in \u001b[0;36mConfluenceLoader.process_page\u001b[0;34m(self, page, include_attachments, include_comments, content_format, ocr_languages, keep_markdown_format, keep_newlines)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 500\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmarkdownify\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m markdownify\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'markdownify'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 29\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Load documents from Confluence\u001b[39;00m\n\u001b[1;32m     24\u001b[0m loader \u001b[38;5;241m=\u001b[39m ConfluenceLoader(\n\u001b[1;32m     25\u001b[0m     url\u001b[38;5;241m=\u001b[39mCONFLUENCE_URL,\n\u001b[1;32m     26\u001b[0m     username\u001b[38;5;241m=\u001b[39mCONFLUENCE_USERNAME,\n\u001b[1;32m     27\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mCONFLUENCE_API_KEY\n\u001b[1;32m     28\u001b[0m )\n\u001b[0;32m---> 29\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFLUENCE_SPACE_KEY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# limit=1,\u001b[39;49;00m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# max_pages=5,\u001b[39;49;00m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_markdown_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     34\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Split documents based on Markdown headers\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit_markdown_documents\u001b[39m(docs):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# Markdown\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/GitHub/Confluence-github-chatbot/pruebas_confluence/lib/python3.12/site-packages/langchain_community/document_loaders/confluence.py:393\u001b[0m, in \u001b[0;36mConfluenceLoader.load\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m--> 393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/GitHub/Confluence-github-chatbot/pruebas_confluence/lib/python3.12/site-packages/langchain_community/document_loaders/confluence.py:321\u001b[0m, in \u001b[0;36mConfluenceLoader._lazy_load\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m space_key:\n\u001b[1;32m    313\u001b[0m     pages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpaginate_request(\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfluence\u001b[38;5;241m.\u001b[39mget_all_pages_from_space,\n\u001b[1;32m    315\u001b[0m         space\u001b[38;5;241m=\u001b[39mspace_key,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    319\u001b[0m         expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontent_format\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,version\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    320\u001b[0m     )\n\u001b[0;32m--> 321\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_pages(\n\u001b[1;32m    322\u001b[0m         pages,\n\u001b[1;32m    323\u001b[0m         include_restricted_content,\n\u001b[1;32m    324\u001b[0m         include_attachments,\n\u001b[1;32m    325\u001b[0m         include_comments,\n\u001b[1;32m    326\u001b[0m         content_format,\n\u001b[1;32m    327\u001b[0m         ocr_languages\u001b[38;5;241m=\u001b[39mocr_languages,\n\u001b[1;32m    328\u001b[0m         keep_markdown_format\u001b[38;5;241m=\u001b[39mkeep_markdown_format,\n\u001b[1;32m    329\u001b[0m         keep_newlines\u001b[38;5;241m=\u001b[39mkeep_newlines,\n\u001b[1;32m    330\u001b[0m     )\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label:\n\u001b[1;32m    333\u001b[0m     pages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpaginate_request(\n\u001b[1;32m    334\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfluence\u001b[38;5;241m.\u001b[39mget_all_pages_by_label,\n\u001b[1;32m    335\u001b[0m         label\u001b[38;5;241m=\u001b[39mlabel,\n\u001b[1;32m    336\u001b[0m         limit\u001b[38;5;241m=\u001b[39mlimit,\n\u001b[1;32m    337\u001b[0m         max_pages\u001b[38;5;241m=\u001b[39mmax_pages,\n\u001b[1;32m    338\u001b[0m     )\n",
            "File \u001b[0;32m~/Documents/GitHub/Confluence-github-chatbot/pruebas_confluence/lib/python3.12/site-packages/langchain_community/document_loaders/confluence.py:478\u001b[0m, in \u001b[0;36mConfluenceLoader.process_pages\u001b[0;34m(self, pages, include_restricted_content, include_attachments, include_comments, content_format, ocr_languages, keep_markdown_format, keep_newlines)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m include_restricted_content \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_public_page(page):\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 478\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_page\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_attachments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_comments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[43mocr_languages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mocr_languages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_markdown_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_markdown_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_newlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_newlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/GitHub/Confluence-github-chatbot/pruebas_confluence/lib/python3.12/site-packages/langchain_community/document_loaders/confluence.py:502\u001b[0m, in \u001b[0;36mConfluenceLoader.process_page\u001b[0;34m(self, page, include_attachments, include_comments, content_format, ocr_languages, keep_markdown_format, keep_newlines)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmarkdownify\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m markdownify\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m--> 502\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    503\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`markdownify` package not found, please run \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install markdownify`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m         )\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_comments \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m keep_markdown_format:\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[0;31mImportError\u001b[0m: `markdownify` package not found, please run `pip install markdownify`"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "from langchain.document_loaders import ConfluenceLoader\n",
        "from langchain.text_splitter import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n",
        "# Attempt to import BeautifulSoup and lxml, handle the exception if lxml is not installed\n",
        "try:\n",
        "    from bs4 import BeautifulSoup\n",
        "except ImportError as e:\n",
        "    raise ImportError(\"Por favor, asegúrate de que la librería 'lxml' está instalada. Usa: pip install lxml\") from e\n",
        "\n",
        "\n",
        "# Environment variable configuration\n",
        "sys.path.append('../')\n",
        "load_dotenv(find_dotenv())\n",
        "\n",
        "# Confluence configuration\n",
        "CONFLUENCE_URL = os.getenv(\"CONFLUENCE_URL\")\n",
        "CONFLUENCE_API_KEY = os.getenv(\"CONFLUENCE_API_KEY\")\n",
        "CONFLUENCE_USERNAME = os.getenv(\"CONFLUENCE_USERNAME\")\n",
        "CONFLUENCE_SPACE_KEY = os.getenv(\"CONFLUENCE_SPACE_KEY\")\n",
        "\n",
        "# Load documents from Confluence\n",
        "loader = ConfluenceLoader(\n",
        "    url=CONFLUENCE_URL,\n",
        "    username=CONFLUENCE_USERNAME,\n",
        "    api_key=CONFLUENCE_API_KEY\n",
        ")\n",
        "docs = loader.load(\n",
        "    space_key=CONFLUENCE_SPACE_KEY,\n",
        "    # limit=1,\n",
        "    # max_pages=5,\n",
        "    keep_markdown_format=True\n",
        ")\n",
        "\n",
        "# Split documents based on Markdown headers\n",
        "def split_markdown_documents(docs):\n",
        "    # Markdown\n",
        "    headers_to_split_on = [\n",
        "            (\"#\", \"Title 1\"),\n",
        "            (\"##\", \"Subtitle 1\"),\n",
        "            (\"###\", \"Subtitle 2\"),\n",
        "    ]\n",
        "    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
        "\n",
        "    # Split based on markdown and add original metadata\n",
        "    md_docs = []\n",
        "    for doc in docs:\n",
        "        md_doc = markdown_splitter.split_text(doc.page_content)\n",
        "        for i in range(len(md_doc)):\n",
        "            md_doc[i].metadata = md_doc[i].metadata | doc.metadata\n",
        "        md_docs.extend(md_doc)\n",
        "\n",
        "    # RecursiveTextSplitter\n",
        "    # Chunk size big enough\n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=512,\n",
        "        chunk_overlap=20,\n",
        "        separators=[r\"\\n\\n\", r\"\\n\", r\"(?<=\\. )\", \" \", \"\"]\n",
        "    )\n",
        "\n",
        "    splitted_docs = splitter.split_documents(md_docs)\n",
        "    return splitted_docs\n",
        "\n",
        "\n",
        "texts = split_markdown_documents(docs)\n",
        "\n",
        "# print first 10 chunks\n",
        "def pretty_print(chunks, limit=10):\n",
        "    for i, chunk in enumerate(chunks[:limit]):\n",
        "        print(f\"Chunk {i+1} Content:\\n{chunk.page_content}\\n---\\nMetadata:\\n{chunk.metadata}\\n{'='*50}\\n\")\n",
        "\n",
        "# pretty_print(texts) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Github ingestion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting os-sys\n",
            "  Using cached os_sys-2.1.4-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting pygubu (from os-sys)\n",
            "  Using cached pygubu-0.35.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: pytz in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from os-sys) (2024.1)\n",
            "Collecting sqlparse (from os-sys)\n",
            "  Using cached sqlparse-0.5.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting progress (from os-sys)\n",
            "  Using cached progress-1.6.tar.gz (7.8 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting tqdm (from os-sys)\n",
            "  Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting progressbar (from os-sys)\n",
            "  Using cached progressbar-2.5.tar.gz (10 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting matplotlib (from os-sys)\n",
            "  Using cached matplotlib-3.8.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from os-sys) (1.26.4)\n",
            "Requirement already satisfied: six in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from os-sys) (1.16.0)\n",
            "Collecting jupyter (from os-sys)\n",
            "  Using cached jupyter-1.0.0-py2.py3-none-any.whl.metadata (995 bytes)\n",
            "Requirement already satisfied: pandas in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from os-sys) (2.2.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from os-sys) (4.12.3)\n",
            "Collecting Eel (from os-sys)\n",
            "  Using cached Eel-0.16.0.tar.gz (24 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting extract-zip (from os-sys)\n",
            "  Using cached extract_zip-1.0.0-py3-none-any.whl.metadata (403 bytes)\n",
            "INFO: pip is looking at multiple versions of os-sys to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting os-sys\n",
            "  Using cached os_sys-2.1.3-py3-none-any.whl.metadata (9.9 kB)\n",
            "  Using cached os_sys-2.1.2-py3-none-any.whl.metadata (9.9 kB)\n",
            "  Using cached os_sys-2.1.1-py3-none-any.whl.metadata (9.9 kB)\n",
            "  Using cached os_sys-2.1.0-py3-none-any.whl.metadata (9.9 kB)\n",
            "  Using cached os_sys-2.0.9-py3-none-any.whl.metadata (9.9 kB)\n",
            "  Using cached os_sys-2.0.8-py3-none-any.whl.metadata (9.9 kB)\n",
            "  Using cached os_sys-2.0.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "INFO: pip is still looking at multiple versions of os-sys to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached os_sys-2.0.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "  Using cached os_sys-2.0.5-py3-none-any.whl.metadata (9.5 kB)\n",
            "  Using cached os_sys-2.0.4-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting webview (from os-sys)\n",
            "  Using cached webview-0.1.5.tar.gz (18 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting os-sys\n",
            "  Using cached os_sys-2.0.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "  Using cached os_sys-2.0.2-py3-none-any.whl.metadata (9.0 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Using cached os_sys-2.0.1-py3-none-any.whl.metadata (9.0 kB)\n",
            "  Using cached os_sys-2.0.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "  Using cached os_sys-1.9.9-py3-none-any.whl.metadata (9.0 kB)\n",
            "  Using cached os_sys-1.9.8-py3-none-any.whl.metadata (9.0 kB)\n",
            "  Using cached os_sys-1.9.7-py3-none-any.whl.metadata (9.0 kB)\n",
            "  Using cached os_sys-1.9.6-py3-none-any.whl.metadata (9.0 kB)\n",
            "  Using cached os_sys-1.9.5-py3-none-any.whl.metadata (9.0 kB)\n",
            "  Using cached os_sys-1.9.4-py3-none-any.whl.metadata (9.0 kB)\n",
            "  Using cached os_sys-1.9.3-py3-none-any.whl (60.4 MB)\n",
            "\u001b[31mERROR: os-sys has an invalid wheel, os-sys has an invalid wheel, could not read 'os_sys-1.9.3.dist-info/WHEEL' file: KeyError(\"There is no item named 'os_sys-1.9.3.dist-info/WHEEL' in the archive\")\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: GitPython in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (3.1.43)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from GitPython) (4.0.11)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->GitPython) (5.0.1)\n",
            "Requirement already satisfied: langchain in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (0.1.17)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (0.6.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.36 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (0.0.36)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.48 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (0.1.48)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (0.1.52)\n",
            "Requirement already satisfied: numpy<2,>=1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain-core<0.2.0,>=0.1.48->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: langchain_community in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (0.0.36)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain_community) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain_community) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain_community) (0.6.5)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.48 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain_community) (0.1.48)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain_community) (0.1.52)\n",
            "Requirement already satisfied: numpy<2,>=1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain_community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain_community) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain-core<0.2.0,>=0.1.48->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain-core<0.2.0,>=0.1.48->langchain_community) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain-core<0.2.0,>=0.1.48->langchain_community) (2.7.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (2024.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.11.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.48->langchain_community) (2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.48->langchain_community) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.48->langchain_community) (2.18.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: PyGithub in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (2.3.0)\n",
            "Requirement already satisfied: pynacl>=1.4.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from PyGithub) (1.5.0)\n",
            "Requirement already satisfied: requests>=2.14.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from PyGithub) (2.31.0)\n",
            "Requirement already satisfied: pyjwt>=2.4.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from pyjwt[crypto]>=2.4.0->PyGithub) (2.8.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from PyGithub) (4.11.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from PyGithub) (2.2.1)\n",
            "Requirement already satisfied: Deprecated in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from PyGithub) (1.2.14)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from pyjwt[crypto]>=2.4.0->PyGithub) (42.0.7)\n",
            "Requirement already satisfied: cffi>=1.4.1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from pynacl>=1.4.0->PyGithub) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests>=2.14.0->PyGithub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests>=2.14.0->PyGithub) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests>=2.14.0->PyGithub) (2024.2.2)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from Deprecated->PyGithub) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub) (2.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install os-sys\n",
        "!pip install GitPython\n",
        "!pip install langchain\n",
        "!pip install langchain_community\n",
        "!pip install PyGithub\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'github'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparsers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LanguageParser\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_text_splitters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Language, RecursiveCharacterTextSplitter\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgithub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Github\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbase64\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Get the home directory path\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'github'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "# from git import Repo # \n",
        "from langchain_community.document_loaders.generic import GenericLoader\n",
        "from langchain_community.document_loaders.parsers import LanguageParser\n",
        "from langchain_text_splitters import Language, RecursiveCharacterTextSplitter\n",
        "from github import Github\n",
        "import base64\n",
        "\n",
        "repo_name = \"JustinWebconnex/bedrock-kendra-chat\"\n",
        "# Get the home directory path\n",
        "home_dir = os.getcwd() \n",
        "GITHUB_API_KEY = os.getenv(\"GITHUB_API_KEY\")\n",
        "# Clone the repository\n",
        "g = Github(GITHUB_API_KEY)\n",
        "repo = g.get_repo(\"JustinWebconnex/bedrock-kendra-chat\")\n",
        "\n",
        "# Create a directory for the repository\n",
        "repo_dir = os.path.join(home_dir, *repo_name.split('/'))\n",
        "os.makedirs(repo_dir, exist_ok=True)\n",
        "\n",
        "# Download files from the repository\n",
        "contents = repo.get_contents(\"\")\n",
        "\n",
        "def download_file(file_content):\n",
        "    if file_content.size > 1000000:  # Check if the file is larger than 1MB\n",
        "        print(f\"File {file_content.path} is too large for direct API download.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        if file_content.encoding == 'base64':\n",
        "            file_data = base64.b64decode(file_content.content)\n",
        "            file_path = os.path.join(repo_dir, file_content.path)\n",
        "            os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
        "\n",
        "            with open(file_path, 'wb') as file:\n",
        "                file.write(file_data)\n",
        "            print(f\"Downloaded {file_content.path}\")\n",
        "        else:\n",
        "            print(f\"Skipped {file_content.path} due to unsupported encoding or empty content\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to download {file_content.path}: {str(e)}\")\n",
        "\n",
        "while contents:\n",
        "    file_content = contents.pop(0)\n",
        "    if file_content.type == \"dir\":\n",
        "        contents.extend(repo.get_contents(file_content.path))\n",
        "    elif file_content.type == \"file\":\n",
        "        download_file(file_content)\n",
        "    elif file_content.type == \"symlink\":\n",
        "        print(f\"Skipped symlink {file_content.path}\")\n",
        "    else:\n",
        "        print(f\"Skipped {file_content.path} due to unsupported file type or content\")\n",
        "\n",
        "# Load supported programming languages using LanguageParser\n",
        "supported_languages = [Language.PYTHON, Language.JS, Language.JAVA, Language.GO, Language.CPP]\n",
        "supported_documents = []\n",
        "\n",
        "for lang in supported_languages:\n",
        "    loader = GenericLoader.from_filesystem(\n",
        "        repo_dir,\n",
        "        glob=\"**/*\",\n",
        "        suffixes=[\".py\", \".js\", \".java\", \".go\", \".cpp\", \".c\", \".cc\", \".cxx\", \".h\", \".hpp\"],\n",
        "        parser=LanguageParser(language=lang, parser_threshold=500),\n",
        "    )\n",
        "    documents = loader.load()\n",
        "    supported_documents.extend(documents)\n",
        "\n",
        "# Load SQL files with specialized handling\n",
        "sql_loader = GenericLoader.from_filesystem(\n",
        "    repo_dir,\n",
        "    glob=\"**/*\",\n",
        "    suffixes=[\".sql\"],\n",
        ")\n",
        "sql_documents = sql_loader.load()\n",
        "\n",
        "# Split SQL files based on CTEs and other SQL constructs\n",
        "sql_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=2000,\n",
        "    chunk_overlap=200,\n",
        "    separators=[\"\\n\\nwith\", \"\\n\\ncreate\", \"\\n\\nalter\", \"\\n\\ndrop\", \"\\n\\ninsert\", \"\\n\\nupdate\", \"\\n\\ndelete\", \"\\n\\nselect\"],\n",
        "    source_separator=\"--8<--\"\n",
        ")\n",
        "sql_texts = sql_splitter.split_documents(sql_documents)\n",
        "\n",
        "# Add metadata for SQL chunks\n",
        "for text in sql_texts:\n",
        "    text.metadata[\"content_type\"] = \"sql\"\n",
        "    if \"with\" in text.page_content.lower():\n",
        "        text.metadata[\"sql_type\"] = \"cte\"\n",
        "    elif any(keyword in text.page_content.lower() for keyword in [\"create\", \"alter\", \"drop\"]):\n",
        "        text.metadata[\"sql_type\"] = \"ddl\"\n",
        "    else:\n",
        "        text.metadata[\"sql_type\"] = \"dml\"\n",
        "\n",
        "# Load unsupported file types using a generic parsing algorithm\n",
        "unsupported_loader = GenericLoader.from_filesystem(\n",
        "    repo_dir,\n",
        "    glob=\"**/*\",\n",
        "    suffixes=[\".yml\", \".txt\", \".dockerfile\"],\n",
        ")\n",
        "unsupported_documents = unsupported_loader.load()\n",
        "\n",
        "# Combine all documents\n",
        "documents = supported_documents + sql_documents + unsupported_documents\n",
        "\n",
        "# Split the documents into chunks\n",
        "supported_texts = []\n",
        "for lang in supported_languages:\n",
        "    lang_documents = [doc for doc in supported_documents if doc.metadata['language'] == lang]\n",
        "    splitter = RecursiveCharacterTextSplitter.from_language(\n",
        "        language=lang, chunk_size=2000, chunk_overlap=200\n",
        "    )\n",
        "    lang_texts = splitter.split_documents(lang_documents)\n",
        "    supported_texts.extend(lang_texts)\n",
        "\n",
        "generic_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
        "unsupported_texts = generic_splitter.split_documents(unsupported_documents)\n",
        "\n",
        "texts = supported_texts + sql_texts + unsupported_texts\n",
        "\n",
        "print(f\"Total number of documents: {len(documents)}\")\n",
        "print(f\"Total number of chunks: {len(texts)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 52 chunks from texts.pkl\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# Load the kendra chat\n",
        "with open('../texts.pkl', 'rb') as f:\n",
        "    texts = pickle.load(f)\n",
        "\n",
        "# Load the sql repo\n",
        "with open('../sql-repo.pkl', 'rb') as f:\n",
        "    sql_repo = pickle.load(f)\n",
        "\n",
        "# Load the platform repo\n",
        "with open('../platform-repo.pkl', 'rb') as f:\n",
        "    platform_chunks = pickle.load(f)\n",
        "\n",
        "# The texts list is now populated with the same chunks\n",
        "print(f\"Loaded {len(texts)} chunks from texts.pkl\")\n",
        "\n",
        "# You can now work with the texts list as before\n",
        "# ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of combined chunks: 1436\n"
          ]
        }
      ],
      "source": [
        "texts.extend(sql_repo)\n",
        "texts.extend(platform_chunks)\n",
        "\n",
        "# Now 'texts' contains all the chunks from the three files\n",
        "print(f\"Total number of combined chunks: {len(texts)}\")\n",
        "\n",
        "# If you need to save the combined list back to a file\n",
        "with open('../combined_chunks.pkl', 'wb') as f:\n",
        "    pickle.dump(texts, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Creation of the training pairs using Bedrock "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6Lzh3-uCRV8j"
      },
      "outputs": [],
      "source": [
        "import boto3\n",
        "import os\n",
        "from langchain_community.chat_models import BedrockChat\n",
        "aws_profile_name = os.getenv('AWS_PROFILE_NAME')\n",
        "# Configuración de AWS\n",
        "session = boto3.Session(profile_name=aws_profile_name)\n",
        "bedrock_client = session.client(\"bedrock-runtime\", region_name=\"us-east-1\")\n",
        "\n",
        "# Función para generar preguntas usando AWS Bedrock\n",
        "def generate_question(chunk_text, metadata):\n",
        "    llm = BedrockChat(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\", region_name=\"us-east-1\", client=bedrock_client)\n",
        "\n",
        "    # Crear el prompt y configurar el mensaje de usuario\n",
        "    prompt = f\"Consider this text: '{chunk_text}' and this metadata '{metadata}'. What would be an appropriate question that a developer would formulate for which this text is a possible answer? return only the question no more text nedeed\"\n",
        "    user_messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "    try:\n",
        "        response = llm.invoke(user_messages)\n",
        "        # Extracción del contenido de la respuesta, asegurándose de obtener el texto de la respuesta\n",
        "        question = response.content\n",
        "        return question\n",
        "    except Exception as e:\n",
        "        print(f\"Error during API call: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "#chunk_text = \"The Python Software Foundation manages the open-source licensing for Python version 3.7 and later.\"\n",
        "#question = generate_question(chunk_text)\n",
        "#print(\"Generated Question:\", question)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ANOkNXHlRbTD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/justinjimenez/Documents/GitHub/Confluence-github-chatbot/pruebas_confluence/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `BedrockChat` was deprecated in LangChain 0.0.34 and will be removed in 0.3. An updated version of the class exists in the langchain-aws package and should be used instead. To use it run `pip install -U langchain-aws` and import as `from langchain_aws import ChatBedrock`.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                              prompt  \\\n",
            "0  How do you set up a Streamlit application that...   \n",
            "1  What is the Python code for setting up an Amaz...   \n",
            "2  How do I set up a sidebar in a Streamlit appli...   \n",
            "3  How do you implement a question-answering syst...   \n",
            "4  What code should be used to retrieve an answer...   \n",
            "\n",
            "                                            response  \\\n",
            "0  from langchain_community.retrievers import Ama...   \n",
            "1  def get_kendra_doc_retriever():\\n    \\n    \\n ...   \n",
            "2  def sidebar():\\n    st.sidebar.title(\"WBX Q&A ...   \n",
            "3  qa = RetrievalQA.from_chain_type(llm=llm, chai...   \n",
            "4  qa = RetrievalQA.from_chain_type(llm=llm, chai...   \n",
            "\n",
            "                                            metadata  \n",
            "0  {'source': '/content/JustinWebconnex/bedrock-k...  \n",
            "1  {'source': '/content/JustinWebconnex/bedrock-k...  \n",
            "2  {'source': '/content/JustinWebconnex/bedrock-k...  \n",
            "3  {'source': '/content/JustinWebconnex/bedrock-k...  \n",
            "4  {'source': '/content/JustinWebconnex/bedrock-k...  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Lista para almacenar los pares prompt-response junto con metadata\n",
        "prompt_response_pairs = []\n",
        "\n",
        "# Procesar cada documento en el conjunto de textos\n",
        "for document in texts:\n",
        "    chunk_text = document.page_content  # Asumiendo que el texto está en el atributo 'page_content'\n",
        "    metadata = document.metadata if hasattr(document, 'metadata') else {}\n",
        "    try:\n",
        "        question = generate_question(chunk_text, metadata)\n",
        "        # question = \"holis\"\n",
        "        if question:  # Asegurarse de que la pregunta fue generada\n",
        "            prompt_response_pairs.append({\n",
        "                'prompt': question,\n",
        "                'response': chunk_text,\n",
        "                'metadata': metadata\n",
        "            })\n",
        "    except Exception as e:\n",
        "        print(f\"Error al generar pregunta para el chunk: {e}\")\n",
        "\n",
        "# Crear un DataFrame con los datos recogidos\n",
        "df = pd.DataFrame(prompt_response_pairs)\n",
        "\n",
        "# Mostrar los primeros registros para verificar\n",
        "print(df.head())\n",
        "\n",
        "# Opcional: guardar el DataFrame como un archivo CSV\n",
        "df.to_csv(\"prompt_response_pairs_github.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "gxJeqn5O6Pty",
        "outputId": "8674a414-335a-45d2-b726-aaac59c18900"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 570,\n  \"fields\": [\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 570,\n        \"samples\": [\n          \"Why did the payment outage occur on March 28th, 2024 that led to double charged payments?\",\n          \"What are the Python style guide recommendations for naming conventions, file naming, function length, and type annotations?\",\n          \"How do I extract the accountId from a path with subpaths?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 568,\n        \"samples\": [\n          \"top Feature The BoxOffice app gives our customers the ability to: - Sell tickets and merchandise onsite - Void transactions made within that session - Check in tickets. - Print Tickets - Send Tickets via Text - Enable tickets for Mobile Pay Pass Availability Apple Android Known Issues Major Errors If a field is added into Director and BoxOffice is not updated with that newest version, BoxOffice will completely crash if the page being loaded uses that new field. Errors that aren\\u2019t actually errors Especially for Shebang era network calls (see the API section below), these don\\u2019t always give back the most helpful status codes and hence often will return 500\\u2019s even though the server didn\\u2019t actually have an error like this. Logging out of a square account in the settings screen does not work in dev env We have no way with square transactions/swippers to do a test charge without actually charging a real card (so you should just set your ticket price to $1) then refund yourself from the Square Dashboard When using a Magtech Swipper on a non-production page with a testing gateway the network call will actually throw and error. Instead, to test a transaction select the input manually option or move to a production page with a live testing gateway. This means that the card you use will be charged! See more details about how tokenization works below. Details Key functionality Processing Credit Card Transactions Square Requires account and Square swipper The transaction is handled completely by Square. We only send order details back to our servers. While Square transactions can be processed on dev environments, logging out of a Square account is only available on release and production environments Magtech Requires a magtech swipper and is used by the majority of our customers. See how Tokenization works below. Magtech utilizes the payment gateways WBX regualarly offers For Adyen transactions, we allow the civilian to input only thier zip code. Because of this, we inject a fake email within the app, that\\u2019s later removed before it\\u2019s stored in our database. Manages a cash box to generate cashier sale reports This feature allows our customers to: Settle their books, especially when a volunteer tries to steal cash Understand which entrances at their event had the most volume Gauge the number of staff needed for future events Prints tickets via Boca Printer or a Star Micronics printer Enables customers to view and void recent orders made on the app Allows customers to check in civilians or text them their ticket Page Builder allows custom BoxOffice overrides for pricing/fees In BoxOffice we charge $0.49 for each ticket verses via Bacon we charge $0.99 Allows customers to purchase tickets on Reserved Seating venues. Tokenization Magetch swippers have our TokenEx private key within it so that when a card is swipped, the details are immediately encrypted before given to the device (iPhone, iPad, etc). Once given to the device, BoxOffice sends the encrypted card data to TokenEx where they give us a billing token. Then BoxOffice takes this billing token and performs a registration for a civilian. Because of this, BoxOffice never actually handles a plaintext CC number. Our dev environments have a completely different TokenEx private key, however, the majority of our swippers availible are only keyed to our production TokenEx vault. This means that: Magtech swippers will only succeed when the environment is set to the production and the transaction is against a live gateway (instead of a tester). Technical Documents Note: for some reason it\\u2019s not letting me add lucid chart to here. Link is below Lucid chart: Box Office App | Lucidchart Client Side Below is a brief layout of the file structure for BoxOffice app .swift\\n    \\u2514\\u2500\\u2500 Controls\\n    \\u2514\\u2500\\u2500 Extensions\\n    \\u2502   \\u2514\\u2500\\u2500 .swift\\n    \\u2514\\u2500\\u2500 Interfaces\\n    \\u251c\\u2500\\u2500 Networking\\n    \\u2502   \\u2514\\u2500\\u2500 BONetworking.swift\\n\\u2514\\u2500\\u2500 Printers\\n\\u2514\\u2500\\u2500 CardReaders\\n\\u2514\\u2500\\u2500 UI\\n    \\u251c\\u2500\\u2500 \\u2502   \\u2514\\u2500\\u2500 ViewController.swift\\n    \\u2502   \\u2514\\u2500\\u2500 ViewModel.swift\\n    \\u2502   \\u2514\\u2500\\u2500 Model.swift]]> UI Layer Info BoxOffice uses what\\u2019s called a Model View Controller (MVC) layout which is an industry standard for mobile apps. This means that within the UI folder for any single view there are three files(see above). The ViewController is where all UI components live and are given dynamic data which usually comes from the ViewModel and Model . However, there is one other important file when diagnosing UI items which is the Main.storyboard (in the root of the Boxoffice folder). This essentially defines all major UI components for any given view, while you can think of the ViewController.swift as the file that initializes them. Network Layer Info All network calls are made within Common/Networking/BONetworking.swift . When a network call errors out, the logging occurs in this file. Most network calls are invoked like this - for this example we will use the{'title': 'Boxoffice App', 'id': '2124447786', 'source': 'https://webconnex.atlassian.net/wiki/spaces/EN/pages/2124447786/Boxoffice+App', 'when': '2024-03-27T16:44:54.338Z'}\",\n          \"What this is: What to do: DB Cleanup:{'title': 'Fail Over a Bricked Database', 'id': '254640212', 'source': 'https://webconnex.atlassian.net/wiki/spaces/EN/pages/254640212/Fail+Over+a+Bricked+Database', 'when': '2019-11-26T08:47:58.815Z'}\",\n          \"Our general deploy flow is outlined below and can also be viewed here . QA For the larger projects, we will have both the product team and our QA engineer(s) involved; that said, the engineers are always responsible for taking the first pass at QA to ensure the deployment works and the feature passes the requirements. QA and Product will identify edge cases and other bugs and work with the team to determine prioritizations of those bugs and edge cases. For smaller hotfixes/refactors, the QA responsibility falls mainly on the engineer to check their work and check for regressions. The QA team can help with E2E tests as needed. Deployments We try to deploy at least once a week. Deployments will occasionally increase during product launches and for hotfixes as required for production support. The deployment flow for a feature will require that feature code gets built at least three times. Even hotfixes will likely go through three reviews, at the very least two. The first tests will take place in one of the dev environments. We currently have two environments for dev testing on our development Kubernetes cluster. The project you are working on will determine which one you are using. We can scale these up and down as needed. After testing and approval, the code can is merged into develop. We usually will batch several merges to develop into a release candidate. Once a release is ready a new branch will be created off of develop and deployed to the release environment for final testing. Pending approval, a new PR is created to master , and from master , a tagged version will be created, which will fire off a CI/CD pipeline in Codefresh and deploy to production. Production Approvals The CI/CD Pipeline for production/tagged builds will require that a manual approval process for each batch of services is executed either through Codefresh or in the #deployments slack channel.{'title': 'QA/Deployment Processes', 'id': '852525065', 'source': 'https://webconnex.atlassian.net/wiki/spaces/EN/pages/852525065', 'when': '2023-03-28T17:27:17.500Z'}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metadata\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 413,\n        \"samples\": [\n          \"{'title': 'Changelog and Updates', 'id': '2376302594', 'source': 'https://webconnex.atlassian.net/wiki/spaces/EN/pages/2376302594/Changelog+and+Updates', 'when': '2024-04-29T21:33:52.271Z'}\",\n          \"{'title': 'Manually Registering a Sole Proprietorship in Twilio', 'id': '2325708810', 'source': 'https://webconnex.atlassian.net/wiki/spaces/EN/pages/2325708810/Manually+Registering+a+Sole+Proprietorship+in+Twilio', 'when': '2024-03-18T20:19:35.453Z'}\",\n          \"{'title': 'Things to do when phishing campaign is identified', 'id': '2379776051', 'source': 'https://webconnex.atlassian.net/wiki/spaces/EN/pages/2379776051/Things+to+do+when+phishing+campaign+is+identified', 'when': '2024-04-18T00:02:40.371Z'}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ceeedff0-2348-4164-af7f-de3c2590ef12\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>response</th>\n",
              "      <th>metadata</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What information and links are available on th...</td>\n",
              "      <td>Welcome to the Engineering Portal Search: larg...</td>\n",
              "      <td>{'title': 'Engineering', 'id': '24969371', 'so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What are the coding standards and best practic...</td>\n",
              "      <td>While this is a living document that will alwa...</td>\n",
              "      <td>{'title': 'GoLang (Go)', 'id': '40894467', 'so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How do we communicate and collaborate effectiv...</td>\n",
              "      <td>Because the current team structure consists of...</td>\n",
              "      <td>{'title': 'Communication', 'id': '40894484', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What are the best practices and guidelines for...</td>\n",
              "      <td>This document is a place where we can note and...</td>\n",
              "      <td>{'title': 'Best Practices and Guidelines', 'id...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What are the coding style guidelines and best ...</td>\n",
              "      <td>For the most part we follow idiomatic Golang p...</td>\n",
              "      <td>{'title': 'Coding Style Guides', 'id': '409600...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>How can I modify the API rate limits for an ac...</td>\n",
              "      <td>1 1 false decimal list false Set the API limit...</td>\n",
              "      <td>{'title': 'Public API Runbook', 'id': '2393047...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>Why did the release of the Purchase Protection...</td>\n",
              "      <td>Postmortem summary Postmortem owner Incident d...</td>\n",
              "      <td>{'title': '2024/04/19 - Purchase Protection Ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>What details should be included in a postmorte...</td>\n",
              "      <td>Postmortem summary Postmortem owner Incident d...</td>\n",
              "      <td>{'title': '2024/04/26 - Tickets displaying Pen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>What steps should be taken to address the issu...</td>\n",
              "      <td>refactor of the codebase to improve readabili...</td>\n",
              "      <td>{'title': '2024/04/26 - Tickets displaying Pen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>569</th>\n",
              "      <td>Why do we get messages on the #blizzard-force-...</td>\n",
              "      <td>The Problem From time to time we get a message...</td>\n",
              "      <td>{'title': 'Asynq Failed Tasks Runbook', 'id': ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>570 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ceeedff0-2348-4164-af7f-de3c2590ef12')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ceeedff0-2348-4164-af7f-de3c2590ef12 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ceeedff0-2348-4164-af7f-de3c2590ef12');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4038ad58-78d7-46ed-a86f-92165b777e80\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4038ad58-78d7-46ed-a86f-92165b777e80')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4038ad58-78d7-46ed-a86f-92165b777e80 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                prompt  \\\n",
              "0    What information and links are available on th...   \n",
              "1    What are the coding standards and best practic...   \n",
              "2    How do we communicate and collaborate effectiv...   \n",
              "3    What are the best practices and guidelines for...   \n",
              "4    What are the coding style guidelines and best ...   \n",
              "..                                                 ...   \n",
              "565  How can I modify the API rate limits for an ac...   \n",
              "566  Why did the release of the Purchase Protection...   \n",
              "567  What details should be included in a postmorte...   \n",
              "568  What steps should be taken to address the issu...   \n",
              "569  Why do we get messages on the #blizzard-force-...   \n",
              "\n",
              "                                              response  \\\n",
              "0    Welcome to the Engineering Portal Search: larg...   \n",
              "1    While this is a living document that will alwa...   \n",
              "2    Because the current team structure consists of...   \n",
              "3    This document is a place where we can note and...   \n",
              "4    For the most part we follow idiomatic Golang p...   \n",
              "..                                                 ...   \n",
              "565  1 1 false decimal list false Set the API limit...   \n",
              "566  Postmortem summary Postmortem owner Incident d...   \n",
              "567  Postmortem summary Postmortem owner Incident d...   \n",
              "568   refactor of the codebase to improve readabili...   \n",
              "569  The Problem From time to time we get a message...   \n",
              "\n",
              "                                              metadata  \n",
              "0    {'title': 'Engineering', 'id': '24969371', 'so...  \n",
              "1    {'title': 'GoLang (Go)', 'id': '40894467', 'so...  \n",
              "2    {'title': 'Communication', 'id': '40894484', '...  \n",
              "3    {'title': 'Best Practices and Guidelines', 'id...  \n",
              "4    {'title': 'Coding Style Guides', 'id': '409600...  \n",
              "..                                                 ...  \n",
              "565  {'title': 'Public API Runbook', 'id': '2393047...  \n",
              "566  {'title': '2024/04/19 - Purchase Protection Ch...  \n",
              "567  {'title': '2024/04/26 - Tickets displaying Pen...  \n",
              "568  {'title': '2024/04/26 - Tickets displaying Pen...  \n",
              "569  {'title': 'Asynq Failed Tasks Runbook', 'id': ...  \n",
              "\n",
              "[570 rows x 3 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"prompt_response_pairs.csv\")\n",
        "df['response'] = df['response'] + df['metadata']\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQxtnePuwQUB"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKVAXiENglWP"
      },
      "outputs": [],
      "source": [
        "# Cargar el segundo DataFrame desde otro CSV\n",
        "df_additional = pd.read_csv(\"prompt_response_pairs_github.csv\")\n",
        "df_additional['response'] = df_additional['response'] + df_additional['metadata']\n",
        "# Fusionar ambos DataFrames\n",
        "df_combined = pd.concat([df, df_additional], ignore_index=True)\n",
        "\n",
        "# Opcional: Eliminar duplicados si es necesario\n",
        "df_combined = df_combined.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "zeV2oSBIgwS0",
        "outputId": "19492369-4d52-4865-f8bb-88a95e963ab8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"582\",\n          \"readme for shebang repo?\",\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          575,\n          \"6\",\n          \"582\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metadata\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          413,\n          \"33\",\n          \"570\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-5dc1ac6a-108b-469b-b8ed-127bb7ffad2d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>response</th>\n",
              "      <th>metadata</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>582</td>\n",
              "      <td>582</td>\n",
              "      <td>570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>582</td>\n",
              "      <td>575</td>\n",
              "      <td>413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>readme for shebang repo?</td>\n",
              "      <td>Shebang\\n\\nShebang contains various API's used...</td>\n",
              "      <td>{'title': 'Python', 'id': '254509193', 'source...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5dc1ac6a-108b-469b-b8ed-127bb7ffad2d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5dc1ac6a-108b-469b-b8ed-127bb7ffad2d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5dc1ac6a-108b-469b-b8ed-127bb7ffad2d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3a22cab4-3317-4e32-b757-16fbc0af4453\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3a22cab4-3317-4e32-b757-16fbc0af4453')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3a22cab4-3317-4e32-b757-16fbc0af4453 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                          prompt  \\\n",
              "count                        582   \n",
              "unique                       582   \n",
              "top     readme for shebang repo?   \n",
              "freq                           1   \n",
              "\n",
              "                                                 response  \\\n",
              "count                                                 582   \n",
              "unique                                                575   \n",
              "top     Shebang\\n\\nShebang contains various API's used...   \n",
              "freq                                                    6   \n",
              "\n",
              "                                                 metadata  \n",
              "count                                                 570  \n",
              "unique                                                413  \n",
              "top     {'title': 'Python', 'id': '254509193', 'source...  \n",
              "freq                                                   33  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df_combined.copy()\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data into train and test sets, with 90% in the train set\n",
        "train_df = df.sample(frac=0.9, random_state=42)\n",
        "test_df = df.drop(train_df.index)\n",
        "\n",
        "# Save the dataframes to .jsonl files\n",
        "train_df.to_json('train.jsonl', orient='records', lines=True)\n",
        "test_df.to_json('test.jsonl', orient='records', lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpOz2x48_brZ"
      },
      "outputs": [],
      "source": [
        "system_message = \"description: This model is trained to provide detailed and professional responses based on Webconnex's internal data sources including Jira, Confluence, and GitHub. It aims to assist Webconnex employees by accessing and interpreting this data effectively. instructions answer_format : Provide a concise, professional answer with relevant metadata. Include URLs or direct references to the data source where the information was found\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbrFgrhG_xYi"
      },
      "source": [
        "# Install necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPG7wEPetFx2"
      },
      "outputs": [],
      "source": [
        "!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    HfArgumentParser,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    logging,\n",
        ")\n",
        "from peft import LoraConfig, PeftModel\n",
        "from trl import SFTTrainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moVo0led-6tu"
      },
      "source": [
        "# Define Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqfbhUZI-4c_"
      },
      "outputs": [],
      "source": [
        "model_name = \"NousResearch/llama-2-7b-chat-hf\" # use this if you have access to the official LLaMA 2 model \"meta-llama/Llama-2-7b-chat-hf\", though keep in mind you'll need to pass a Hugging Face key argument\n",
        "dataset_name = \"/content/train.jsonl\"\n",
        "new_model = \"llama-2-7b-custom\"\n",
        "lora_r = 64\n",
        "lora_alpha = 16\n",
        "lora_dropout = 0.1\n",
        "use_4bit = True\n",
        "bnb_4bit_compute_dtype = \"float16\"\n",
        "bnb_4bit_quant_type = \"nf4\"\n",
        "use_nested_quant = False\n",
        "output_dir = \"./results\"\n",
        "num_train_epochs = 1\n",
        "fp16 = False\n",
        "bf16 = False\n",
        "per_device_train_batch_size = 4\n",
        "per_device_eval_batch_size = 4\n",
        "gradient_accumulation_steps = 1\n",
        "gradient_checkpointing = True\n",
        "max_grad_norm = 0.3\n",
        "learning_rate = 2e-4\n",
        "weight_decay = 0.001\n",
        "optim = \"paged_adamw_32bit\"\n",
        "lr_scheduler_type = \"constant\"\n",
        "max_steps = -1\n",
        "warmup_ratio = 0.03\n",
        "group_by_length = True\n",
        "save_steps = 25\n",
        "logging_steps = 5\n",
        "max_seq_length = None\n",
        "packing = False\n",
        "device_map = {\"\": 0}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-J5p5KS_MZY"
      },
      "source": [
        "#Load Datasets and Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "51fe372773894fd884a59c0b250fa9df",
            "32f49e7b9b704bc9813616b8c0beeb76",
            "32f9cf6737c24ab0bf74e4ac55e1b85f",
            "6c0cd5b7eb464abf9a63594a5fbdfbfa",
            "21aa5c3dc9804902933e64edbd02b429",
            "9a3a76dff0df4ee09cdfe599ec7da7d5",
            "c7cbd98d40ac45ddbeee90a44fc722db",
            "2a86e006a1b84df4bb1b62422dd274d7",
            "883cf300966942088acdacbacaed759b",
            "59bb2b4030f84fcb9b46f6c96e1f142e",
            "0176a3dab2be4553a1ba8165b40c0255",
            "93fc39db30c846d199bd3dfc01de9a6b",
            "e1634695d9c94c48882615c3bdeee8f9",
            "06ec895dfe0c44908c4e967bf930bfc0",
            "cda5ef8eb7e0476bb34536f811ecfcce",
            "020026de97e94b5a8a17bd7d62779ffc",
            "2f3ace2a15884501b6560d4934b4657b",
            "6112864ff60c41b29aebdb233f5c16b0",
            "62e95816b9e743d79655c0c663b195d1",
            "9d5f5bb29c17489a9d03fcf0a7acc1dd",
            "02cdec2f4c654d36a8b43edc2ed799e7",
            "51e55c91aecb4c5b8bd9cd1177b3fc34",
            "2f64918a98e24fd598500c2a112536e2",
            "c71a553e99a3433eb03356f88d8eca8a",
            "b3697c4e81f24695ab21a287eb1bdc5d",
            "39772a1129a9409b89b2d39c0317fdf0",
            "8fb0425962c546829b6a6404665cbf48",
            "dd705d620eb740568ad22285ce44c633",
            "585e7653ca984c41973083c3b49eaeb6",
            "a983b8ac01e6435f84050b137855c720",
            "dd8334e301674854b6dd8d76026cbdd9",
            "0be7a9def12d4c9d9a7fd7daef3a9c58",
            "b2261aee99b243d9ad9fad1fa1dd4b1a"
          ]
        },
        "id": "qf1qxbiF-x6p",
        "outputId": "31f9f503-ce8e-475e-9f68-244d8a0f2e29"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51fe372773894fd884a59c0b250fa9df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:159: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93fc39db30c846d199bd3dfc01de9a6b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/511 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f64918a98e24fd598500c2a112536e2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/57 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='121' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [121/128 42:40 < 02:30, 0.05 it/s, Epoch 0.94/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.730200</td>\n",
              "      <td>2.886348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.699400</td>\n",
              "      <td>2.713974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>2.500100</td>\n",
              "      <td>2.561215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.465800</td>\n",
              "      <td>2.408849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>2.012100</td>\n",
              "      <td>2.268775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.345300</td>\n",
              "      <td>2.171365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>1.874500</td>\n",
              "      <td>2.117732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>2.120100</td>\n",
              "      <td>2.087240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>2.171600</td>\n",
              "      <td>2.070149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.908700</td>\n",
              "      <td>2.040256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>1.736000</td>\n",
              "      <td>2.025035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.115100</td>\n",
              "      <td>2.015980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>1.526400</td>\n",
              "      <td>2.014095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.995900</td>\n",
              "      <td>2.006722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>2.025600</td>\n",
              "      <td>1.994861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.872900</td>\n",
              "      <td>1.985011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>1.593200</td>\n",
              "      <td>1.979729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.225400</td>\n",
              "      <td>1.986357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>1.244100</td>\n",
              "      <td>1.977417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>2.129700</td>\n",
              "      <td>1.975325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>1.997000</td>\n",
              "      <td>1.966032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>1.780100</td>\n",
              "      <td>1.956343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>1.579000</td>\n",
              "      <td>1.949533</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/8 00:18 < 00:45, 0.11 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Load datasets\n",
        "train_dataset = load_dataset('json', data_files='/content/train.jsonl', split=\"train\")\n",
        "valid_dataset = load_dataset('json', data_files='/content/test.jsonl', split=\"train\")\n",
        "\n",
        "# Preprocess datasets\n",
        "#train_dataset_mapped = train_dataset.map(lambda examples: {'text': [f'[INST] <<SYS>>\\n{system_message.strip()}\\n<</SYS>>\\n\\n' + prompt + ' [/INST] ' + response for prompt, response in zip(examples['prompt'], examples['response'])]}, batched=True)\n",
        "#valid_dataset_mapped = valid_dataset.map(lambda examples: {'text': [f'[INST] <<SYS>>\\n{system_message.strip()}\\n<</SYS>>\\n\\n' + prompt + ' [/INST] ' + response for prompt, response in zip(examples['prompt'], examples['response'])]}, batched=True)\n",
        "# Preprocess datasets\n",
        "def format_data(example):\n",
        "    formatted_text = f'[INST] <<SYS>>\\n{system_message.strip()}\\n<</SYS>>\\n\\n{example[\"prompt\"]} [/INST] {example[\"response\"]}'\n",
        "    return {'text': formatted_text}\n",
        "\n",
        "# Aplicar formateo a los datasets\n",
        "train_dataset_mapped = train_dataset.map(format_data, batched=False)\n",
        "valid_dataset_mapped = valid_dataset.map(format_data, batched=False)\n",
        "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=use_4bit,\n",
        "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
        "    bnb_4bit_compute_dtype=compute_dtype,\n",
        "    bnb_4bit_use_double_quant=use_nested_quant,\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=device_map\n",
        ")\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=lora_alpha,\n",
        "    lora_dropout=lora_dropout,\n",
        "    r=lora_r,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "# Set training parameters\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    per_device_train_batch_size=per_device_train_batch_size,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    optim=optim,\n",
        "    save_steps=save_steps,\n",
        "    logging_steps=logging_steps,\n",
        "    learning_rate=learning_rate,\n",
        "    weight_decay=weight_decay,\n",
        "    fp16=fp16,\n",
        "    bf16=bf16,\n",
        "    max_grad_norm=max_grad_norm,\n",
        "    max_steps=max_steps,\n",
        "    warmup_ratio=warmup_ratio,\n",
        "    group_by_length=group_by_length,\n",
        "    lr_scheduler_type=lr_scheduler_type,\n",
        "    report_to=\"all\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=5  # Evaluate every 20 steps\n",
        ")\n",
        "# Set supervised fine-tuning parameters\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=train_dataset_mapped,\n",
        "    eval_dataset=valid_dataset_mapped,  # Pass validation dataset here\n",
        "    peft_config=peft_config,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        "    packing=packing,\n",
        ")\n",
        "trainer.train()\n",
        "trainer.model.save_pretrained(new_model)\n",
        "\n",
        "# Cell 4: Test the model\n",
        "logging.set_verbosity(logging.CRITICAL)\n",
        "prompt = f\"[INST] <<SYS>>\\n{system_message}\\n<</SYS>>\\n\\nWrite a function that reverses a string. [/INST]\" # replace the command here with something relevant to your task\n",
        "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\n",
        "result = pipe(prompt)\n",
        "print(result[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6fux9om_c4-"
      },
      "source": [
        "#Run Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hxQ_Ero2IJe"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "prompt = f\"[INST] <<SYS>>\\n{system_message}\\n<</SYS>>\\n\\nexplain to me the steps for a new hire in the company. [/INST]\" # replace the command here with something relevant to your task\n",
        "num_new_tokens = 100  # change to the number of new tokens you want to generate\n",
        "\n",
        "# Count the number of tokens in the prompt\n",
        "num_prompt_tokens = len(tokenizer(prompt)['input_ids'])\n",
        "\n",
        "# Calculate the maximum length for the generation\n",
        "max_length = num_prompt_tokens + num_new_tokens\n",
        "\n",
        "gen = pipeline('text-generation', model=model, tokenizer=tokenizer, max_length=max_length)\n",
        "result = gen(prompt)\n",
        "print(result[0]['generated_text'].replace(prompt, ''))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko6UkINu_qSx"
      },
      "source": [
        "#Merge the model and store in Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgKCL7fTyp9u"
      },
      "outputs": [],
      "source": [
        "# Merge and save the fine-tuned model\n",
        "from google.colab import drive\n",
        "import torch\n",
        "\n",
        "# Libera toda la memoria caché no utilizada\n",
        "torch.cuda.empty_cache()\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/llama-2-7b-custom\"  # change to your preferred path\n",
        "\n",
        "# Reload model in FP16 and merge it with LoRA weights\n",
        "try:\n",
        "    base_model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        low_cpu_mem_usage=True,\n",
        "        use_cache=False,\n",
        "        torch_dtype=torch.float16,\n",
        "        device_map=device_map,\n",
        "    )\n",
        "    model = PeftModel.from_pretrained(base_model, new_model)\n",
        "    model = model.merge_and_unload()\n",
        "    print(\"Modelo cargado y combinado con éxito\")\n",
        "except RuntimeError as e:\n",
        "    print(f\"No se pudo cargar el modelo debido a un error de memoria: {e}\")\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Reload tokenizer to save it\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "# Save the merged model\n",
        "model.save_pretrained(model_path)\n",
        "tokenizer.save_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do-dFdE5zWGO"
      },
      "source": [
        "# Load a fine-tuned model from Drive and run inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xg6nHPsLzMw-"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/llama-2-7b-custom\"  # change to the path where your model is saved\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBK2aE2KzZ05"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "prompt = \"What is 2 + 2?\"  # change to your desired prompt\n",
        "gen = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
        "result = gen(prompt)\n",
        "print(result[0]['generated_text'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0176a3dab2be4553a1ba8165b40c0255": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "020026de97e94b5a8a17bd7d62779ffc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02cdec2f4c654d36a8b43edc2ed799e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06ec895dfe0c44908c4e967bf930bfc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62e95816b9e743d79655c0c663b195d1",
            "max": 511,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d5f5bb29c17489a9d03fcf0a7acc1dd",
            "value": 511
          }
        },
        "0be7a9def12d4c9d9a7fd7daef3a9c58": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21aa5c3dc9804902933e64edbd02b429": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a86e006a1b84df4bb1b62422dd274d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f3ace2a15884501b6560d4934b4657b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f64918a98e24fd598500c2a112536e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c71a553e99a3433eb03356f88d8eca8a",
              "IPY_MODEL_b3697c4e81f24695ab21a287eb1bdc5d",
              "IPY_MODEL_39772a1129a9409b89b2d39c0317fdf0"
            ],
            "layout": "IPY_MODEL_8fb0425962c546829b6a6404665cbf48"
          }
        },
        "32f49e7b9b704bc9813616b8c0beeb76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a3a76dff0df4ee09cdfe599ec7da7d5",
            "placeholder": "​",
            "style": "IPY_MODEL_c7cbd98d40ac45ddbeee90a44fc722db",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "32f9cf6737c24ab0bf74e4ac55e1b85f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a86e006a1b84df4bb1b62422dd274d7",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_883cf300966942088acdacbacaed759b",
            "value": 2
          }
        },
        "39772a1129a9409b89b2d39c0317fdf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0be7a9def12d4c9d9a7fd7daef3a9c58",
            "placeholder": "​",
            "style": "IPY_MODEL_b2261aee99b243d9ad9fad1fa1dd4b1a",
            "value": " 57/57 [00:00&lt;00:00, 441.64 examples/s]"
          }
        },
        "51e55c91aecb4c5b8bd9cd1177b3fc34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51fe372773894fd884a59c0b250fa9df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_32f49e7b9b704bc9813616b8c0beeb76",
              "IPY_MODEL_32f9cf6737c24ab0bf74e4ac55e1b85f",
              "IPY_MODEL_6c0cd5b7eb464abf9a63594a5fbdfbfa"
            ],
            "layout": "IPY_MODEL_21aa5c3dc9804902933e64edbd02b429"
          }
        },
        "585e7653ca984c41973083c3b49eaeb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59bb2b4030f84fcb9b46f6c96e1f142e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6112864ff60c41b29aebdb233f5c16b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62e95816b9e743d79655c0c663b195d1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c0cd5b7eb464abf9a63594a5fbdfbfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59bb2b4030f84fcb9b46f6c96e1f142e",
            "placeholder": "​",
            "style": "IPY_MODEL_0176a3dab2be4553a1ba8165b40c0255",
            "value": " 2/2 [01:11&lt;00:00, 32.70s/it]"
          }
        },
        "883cf300966942088acdacbacaed759b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8fb0425962c546829b6a6404665cbf48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93fc39db30c846d199bd3dfc01de9a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1634695d9c94c48882615c3bdeee8f9",
              "IPY_MODEL_06ec895dfe0c44908c4e967bf930bfc0",
              "IPY_MODEL_cda5ef8eb7e0476bb34536f811ecfcce"
            ],
            "layout": "IPY_MODEL_020026de97e94b5a8a17bd7d62779ffc"
          }
        },
        "9a3a76dff0df4ee09cdfe599ec7da7d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d5f5bb29c17489a9d03fcf0a7acc1dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a983b8ac01e6435f84050b137855c720": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2261aee99b243d9ad9fad1fa1dd4b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3697c4e81f24695ab21a287eb1bdc5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a983b8ac01e6435f84050b137855c720",
            "max": 57,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd8334e301674854b6dd8d76026cbdd9",
            "value": 57
          }
        },
        "c71a553e99a3433eb03356f88d8eca8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd705d620eb740568ad22285ce44c633",
            "placeholder": "​",
            "style": "IPY_MODEL_585e7653ca984c41973083c3b49eaeb6",
            "value": "Map: 100%"
          }
        },
        "c7cbd98d40ac45ddbeee90a44fc722db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cda5ef8eb7e0476bb34536f811ecfcce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02cdec2f4c654d36a8b43edc2ed799e7",
            "placeholder": "​",
            "style": "IPY_MODEL_51e55c91aecb4c5b8bd9cd1177b3fc34",
            "value": " 511/511 [00:00&lt;00:00, 594.60 examples/s]"
          }
        },
        "dd705d620eb740568ad22285ce44c633": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd8334e301674854b6dd8d76026cbdd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e1634695d9c94c48882615c3bdeee8f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f3ace2a15884501b6560d4934b4657b",
            "placeholder": "​",
            "style": "IPY_MODEL_6112864ff60c41b29aebdb233f5c16b0",
            "value": "Map: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
